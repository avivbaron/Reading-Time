{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Reading_Time_CV_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSUAwwjnJKjq"
      },
      "source": [
        "# CV Final Project: Reading Time By Aviv Bar-on#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urAtNvHTJKjy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pynput.mouse import Button, Controller"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlN59EkyJKjz"
      },
      "source": [
        "1. Load a Classifiers for the face and eyes detection. Using 'haarcascades'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_cpJkGJKj0"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kp80D5oJKj1"
      },
      "source": [
        "2. Initialize mouse controller. Using pynput library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syqOcmpiJKj1"
      },
      "source": [
        "mouse = Controller()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKeauueOJKj2"
      },
      "source": [
        "3. Initialize detector parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioeR-DuoJKj2"
      },
      "source": [
        "detector_params = cv2.SimpleBlobDetector_Params()\n",
        "detector_params.filterByArea = True\n",
        "detector_params.maxArea = 1500\n",
        "detector = cv2.SimpleBlobDetector_create(detector_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ofDXvNrJKj2"
      },
      "source": [
        "Detect Faces Function: Using the cascade classifier for face detecting.\n",
        "The function get an image and classifier and return the frame of the biggest detected face because there some things in the background that seems to look like face sometime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7RnpvPiJKj3"
      },
      "source": [
        "def detect_faces(img, classifier):\n",
        "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    coords = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
        "    if len(coords) > 1:\n",
        "        biggest = (0, 0, 0, 0)\n",
        "        for i in coords:\n",
        "            if i[3] > biggest[3]:\n",
        "                biggest = i\n",
        "        biggest = np.array([i], np.int32)\n",
        "    elif len(coords) == 1:\n",
        "        biggest = coords\n",
        "    else:\n",
        "        return None\n",
        "    for (x, y, w, h) in biggest:\n",
        "        frame = img[y:y + h, x:x + w]\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk6GTuyIJKj4"
      },
      "source": [
        "Detect Eyes Funtion: Using cascade classifier to the detect the eyes area and then find both eyes.\n",
        "The function get an image and classifier and return seperate the left eye and right eye."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qto2BlAkJKj4"
      },
      "source": [
        "def detect_eyes(img, classifier):\n",
        "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    eyes = eye_cascade.detectMultiScale(gray_frame, 1.3, 7) # detect eyes\n",
        "    width = np.size(img, 1) # get face frame width\n",
        "    height = np.size(img, 0) # get face frame height\n",
        "    left_eye = None\n",
        "    right_eye = None\n",
        "    for (x, y, w, h) in eyes:\n",
        "        if y > height / 2:\n",
        "            pass\n",
        "        eyecenter = x + w / 2  # get the eye vertical center, to seperate the eyes\n",
        "        if eyecenter < width * 0.5:\n",
        "            left_eye = img[y:y + h, x:x + w]\n",
        "        else:\n",
        "            right_eye = img[y:y + h, x:x + w]\n",
        "    return left_eye, right_eye"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc4wbOSGJKj5"
      },
      "source": [
        "Cut eyebrows function: the eyebrows always take ~25% of the image starting from the top, so if we will take out this part it will be more easy to detect the pupil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVH9FLRIJKj5"
      },
      "source": [
        "def cut_eyebrows(img):\n",
        "    height, width = img.shape[:2]\n",
        "    eyebrow_h = int(height / 4)\n",
        "    img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxO0Lv1TJKj6"
      },
      "source": [
        "Blob Process function: Processing the image of the eyes to detect the pupil.\n",
        "The function return keypoints of the pupils."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIHb1IypJKj6"
      },
      "source": [
        "def blob_process(img, threshold, detector):\n",
        "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, img = cv2.threshold(gray_frame, threshold, 255, cv2.THRESH_BINARY)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    img = cv2.bilateralFilter(img, 10, 15, 15)\n",
        "    img = cv2.erode(img, kernel, iterations=2)\n",
        "    img = cv2.dilate(img, kernel, iterations=4)\n",
        "    img = cv2.medianBlur(img, 5)\n",
        "    keypoints = detector.detect(img)\n",
        "    return keypoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYJW2dXJKj6"
      },
      "source": [
        "The issue with OpenCV track bars is that they require a function that will happen on each track bar movement. We donâ€™t need any sort of action, we only need the value of our track bar, so we create a nothing() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7jkO0zvJKj6"
      },
      "source": [
        "def nothing(x):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab6YGF9JJKj7"
      },
      "source": [
        "Main Function: We are using laptop's webcam to detect our eyes while reading something in the laptop so that when we are looking down and got to the bottom of the screen, the cam will detect that and scroll the screen up for us.\n",
        "\n",
        "Threshold Bar: The threshold need to change because of the light or distance from the laptop, there is a bar that make it easy to siut the threshold for the specific condition.\n",
        "\n",
        "While we are reading the frames from the camera, the frames go through face detecting, eye detecting in face, deleting eyebrows and finally processed to find the keypoints of the pupils.\n",
        "\n",
        "Later, we are using one of our keypoints parameter that change when we are looking down the screen and gets bigger. when that parameter is over 15.5 the screen will scroll up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Iuu5mwJKj7"
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "cv2.namedWindow('Eye Detector')\n",
        "cv2.createTrackbar('threshold', 'Eye Detector', 42, 255, nothing) # the threshold is changing by light and distance\n",
        "y = 0 # Importent when the first frame will not detect our eyes\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "\n",
        "    if(ret == True): \n",
        "        face_frame = detect_faces(frame, face_cascade)\n",
        "        if face_frame is not None:\n",
        "            eyes = detect_eyes(face_frame, eye_cascade)\n",
        "            \n",
        "            for eye in eyes:\n",
        "                if eye is not None:\n",
        "                    threshold = cv2.getTrackbarPos('threshold', 'Eye Detector')\n",
        "                    eye = cut_eyebrows(eye)\n",
        "                    keypoints = blob_process(eye, threshold, detector)\n",
        "                    eye = cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "            \n",
        "            for keypoint in keypoints:\n",
        "                y = keypoint.pt[1]\n",
        "                \n",
        "            if y is None:\n",
        "                print(\"None\")\n",
        "                \n",
        "            elif y > 15.5:\n",
        "                mouse.scroll(0,-0.3)\n",
        "                \n",
        "        cv2.imshow('Eye Detector', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "cv2.waitKey(1);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}